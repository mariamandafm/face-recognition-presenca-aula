{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mariamandafm/face-recognition-presenca-aula/blob/master/Reconhecimento_facial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zm7qpB7Acjw3",
        "outputId": "59aa51b3-37be-4632-b6d5-105e7dcd45be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting face_recognition\n",
            "  Downloading face_recognition-1.3.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting face-recognition-models>=0.3.0 (from face_recognition)\n",
            "  Downloading face_recognition_models-0.3.0.tar.gz (100.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.1/100.1 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.10/dist-packages (from face_recognition) (8.1.7)\n",
            "Requirement already satisfied: dlib>=19.7 in /usr/local/lib/python3.10/dist-packages (from face_recognition) (19.24.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from face_recognition) (1.23.5)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from face_recognition) (9.4.0)\n",
            "Building wheels for collected packages: face-recognition-models\n",
            "  Building wheel for face-recognition-models (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for face-recognition-models: filename=face_recognition_models-0.3.0-py2.py3-none-any.whl size=100566170 sha256=22105c4d3ee8d0f142faeae954c02011ef850003835066983e9a57a80887487c\n",
            "  Stored in directory: /root/.cache/pip/wheels/7a/eb/cf/e9eced74122b679557f597bb7c8e4c739cfcac526db1fd523d\n",
            "Successfully built face-recognition-models\n",
            "Installing collected packages: face-recognition-models, face_recognition\n",
            "Successfully installed face-recognition-models-0.3.0 face_recognition-1.3.0\n"
          ]
        }
      ],
      "source": [
        "!pip install face_recognition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HWWdw2U5XyHx",
        "outputId": "e112ac5c-4675-4a69-c543-ffb41c4da59c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting encode_faces.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile encode_faces.py\n",
        "# USAGE\n",
        "# python encode_faces.py --dataset dataset --encodings encodings.pickle\n",
        "\n",
        "# import the necessary packages\n",
        "from imutils import paths\n",
        "import face_recognition\n",
        "import argparse\n",
        "import pickle\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "# construct the argument parser and parse the arguments\n",
        "ap = argparse.ArgumentParser()\n",
        "ap.add_argument(\"-i\", \"--dataset\", required=True,\n",
        "\thelp=\"path to input directory of faces + images\")\n",
        "ap.add_argument(\"-e\", \"--encodings\", required=True,\n",
        "\thelp=\"path to serialized db of facial encodings\")\n",
        "ap.add_argument(\"-d\", \"--detection-method\", type=str, default=\"cnn\",\n",
        "\thelp=\"face detection model to use: either `hog` or `cnn`\")\n",
        "args = vars(ap.parse_args())\n",
        "\n",
        "# grab the paths to the input images in our dataset\n",
        "print(\"[INFO] quantifying faces...\")\n",
        "imagePaths = list(paths.list_images(args[\"dataset\"]))\n",
        "\n",
        "# initialize the list of known encodings and known names\n",
        "knownEncodings = []\n",
        "knownNames = []\n",
        "\n",
        "# loop over the image paths\n",
        "for (i, imagePath) in enumerate(imagePaths):\n",
        "\t# extract the person name from the image path\n",
        "\tprint(\"[INFO] processing image {}/{}\".format(i + 1,\n",
        "\t\tlen(imagePaths)))\n",
        "\tname = imagePath.split(os.path.sep)[-2]\n",
        "\n",
        "\t# load the input image and convert it from RGB (OpenCV ordering)\n",
        "\t# to dlib ordering (RGB)\n",
        "\timage = cv2.imread(imagePath)\n",
        "\trgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "\t# detect the (x, y)-coordinates of the bounding boxes\n",
        "\t# corresponding to each face in the input image\n",
        "\tboxes = face_recognition.face_locations(rgb,\n",
        "\t\tmodel=args[\"detection_method\"])\n",
        "\n",
        "\t# compute the facial embedding for the face\n",
        "\tencodings = face_recognition.face_encodings(rgb, boxes)\n",
        "\n",
        "\t# loop over the encodings\n",
        "\tfor encoding in encodings:\n",
        "\t\t# add each encoding + name to our set of known names and\n",
        "\t\t# encodings\n",
        "\t\tknownEncodings.append(encoding)\n",
        "\t\tknownNames.append(name)\n",
        "\n",
        "# dump the facial encodings + names to disk\n",
        "print(\"[INFO] serializing encodings...\")\n",
        "data = {\"encodings\": knownEncodings, \"names\": knownNames}\n",
        "f = open(args[\"encodings\"], \"wb\")\n",
        "f.write(pickle.dumps(data))\n",
        "f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HM2PSQ0ze7y-",
        "outputId": "ab06430f-40cb-4cd9-f54f-cad9c2218530"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] quantifying faces...\n",
            "[INFO] processing image 1/175\n",
            "[INFO] processing image 2/175\n",
            "[INFO] processing image 3/175\n",
            "[INFO] processing image 4/175\n",
            "[INFO] processing image 5/175\n",
            "[INFO] processing image 6/175\n",
            "[INFO] processing image 7/175\n",
            "[INFO] processing image 8/175\n",
            "[INFO] processing image 9/175\n",
            "[INFO] processing image 10/175\n",
            "[INFO] processing image 11/175\n",
            "[INFO] processing image 12/175\n",
            "[INFO] processing image 13/175\n",
            "[INFO] processing image 14/175\n",
            "[INFO] processing image 15/175\n",
            "[INFO] processing image 16/175\n",
            "[INFO] processing image 17/175\n",
            "[INFO] processing image 18/175\n",
            "[INFO] processing image 19/175\n",
            "[INFO] processing image 20/175\n",
            "[INFO] processing image 21/175\n",
            "[INFO] processing image 22/175\n",
            "[INFO] processing image 23/175\n",
            "[INFO] processing image 24/175\n",
            "[INFO] processing image 25/175\n",
            "[INFO] processing image 26/175\n",
            "[INFO] processing image 27/175\n",
            "[INFO] processing image 28/175\n",
            "[INFO] processing image 29/175\n",
            "[INFO] processing image 30/175\n",
            "[INFO] processing image 31/175\n",
            "[INFO] processing image 32/175\n",
            "[INFO] processing image 33/175\n",
            "[INFO] processing image 34/175\n",
            "[INFO] processing image 35/175\n",
            "[INFO] processing image 36/175\n",
            "[INFO] processing image 37/175\n",
            "[INFO] processing image 38/175\n",
            "[INFO] processing image 39/175\n",
            "[INFO] processing image 40/175\n",
            "[INFO] processing image 41/175\n",
            "[INFO] processing image 42/175\n",
            "[INFO] processing image 43/175\n",
            "[INFO] processing image 44/175\n",
            "[INFO] processing image 45/175\n",
            "[INFO] processing image 46/175\n",
            "[INFO] processing image 47/175\n",
            "[INFO] processing image 48/175\n",
            "[INFO] processing image 49/175\n",
            "[INFO] processing image 50/175\n",
            "[INFO] processing image 51/175\n",
            "[INFO] processing image 52/175\n",
            "[INFO] processing image 53/175\n",
            "[INFO] processing image 54/175\n",
            "[INFO] processing image 55/175\n",
            "[INFO] processing image 56/175\n",
            "[INFO] processing image 57/175\n",
            "[INFO] processing image 58/175\n",
            "[INFO] processing image 59/175\n",
            "[INFO] processing image 60/175\n",
            "[INFO] processing image 61/175\n",
            "[INFO] processing image 62/175\n",
            "[INFO] processing image 63/175\n",
            "[INFO] processing image 64/175\n",
            "[INFO] processing image 65/175\n",
            "[INFO] processing image 66/175\n",
            "[INFO] processing image 67/175\n",
            "[INFO] processing image 68/175\n",
            "[INFO] processing image 69/175\n",
            "[INFO] processing image 70/175\n",
            "[INFO] processing image 71/175\n",
            "[INFO] processing image 72/175\n",
            "[INFO] processing image 73/175\n",
            "[INFO] processing image 74/175\n",
            "[INFO] processing image 75/175\n",
            "[INFO] processing image 76/175\n",
            "[INFO] processing image 77/175\n",
            "[INFO] processing image 78/175\n",
            "[INFO] processing image 79/175\n",
            "[INFO] processing image 80/175\n",
            "[INFO] processing image 81/175\n",
            "[INFO] processing image 82/175\n",
            "[INFO] processing image 83/175\n",
            "[INFO] processing image 84/175\n",
            "[INFO] processing image 85/175\n",
            "[INFO] processing image 86/175\n",
            "[INFO] processing image 87/175\n",
            "[INFO] processing image 88/175\n",
            "[INFO] processing image 89/175\n",
            "[INFO] processing image 90/175\n",
            "[INFO] processing image 91/175\n",
            "[INFO] processing image 92/175\n",
            "[INFO] processing image 93/175\n",
            "[INFO] processing image 94/175\n",
            "[INFO] processing image 95/175\n",
            "[INFO] processing image 96/175\n",
            "[INFO] processing image 97/175\n",
            "[INFO] processing image 98/175\n",
            "[INFO] processing image 99/175\n",
            "[INFO] processing image 100/175\n",
            "[INFO] processing image 101/175\n",
            "[INFO] processing image 102/175\n",
            "[INFO] processing image 103/175\n",
            "[INFO] processing image 104/175\n",
            "[INFO] processing image 105/175\n",
            "[INFO] processing image 106/175\n",
            "[INFO] processing image 107/175\n",
            "[INFO] processing image 108/175\n",
            "[INFO] processing image 109/175\n",
            "[INFO] processing image 110/175\n",
            "[INFO] processing image 111/175\n",
            "[INFO] processing image 112/175\n",
            "[INFO] processing image 113/175\n",
            "[INFO] processing image 114/175\n",
            "[INFO] processing image 115/175\n",
            "[INFO] processing image 116/175\n",
            "[INFO] processing image 117/175\n",
            "[INFO] processing image 118/175\n",
            "[INFO] processing image 119/175\n",
            "[INFO] processing image 120/175\n",
            "[INFO] processing image 121/175\n",
            "[INFO] processing image 122/175\n",
            "[INFO] processing image 123/175\n",
            "[INFO] processing image 124/175\n",
            "[INFO] processing image 125/175\n",
            "[INFO] processing image 126/175\n",
            "[INFO] processing image 127/175\n",
            "[INFO] processing image 128/175\n",
            "[INFO] processing image 129/175\n",
            "[INFO] processing image 130/175\n",
            "[INFO] processing image 131/175\n",
            "[INFO] processing image 132/175\n",
            "[INFO] processing image 133/175\n",
            "[INFO] processing image 134/175\n",
            "[INFO] processing image 135/175\n",
            "[INFO] processing image 136/175\n",
            "[INFO] processing image 137/175\n",
            "[INFO] processing image 138/175\n",
            "[INFO] processing image 139/175\n",
            "[INFO] processing image 140/175\n",
            "[INFO] processing image 141/175\n",
            "[INFO] processing image 142/175\n",
            "[INFO] processing image 143/175\n",
            "[INFO] processing image 144/175\n",
            "[INFO] processing image 145/175\n",
            "[INFO] processing image 146/175\n",
            "[INFO] processing image 147/175\n",
            "[INFO] processing image 148/175\n",
            "[INFO] processing image 149/175\n",
            "[INFO] processing image 150/175\n",
            "[INFO] processing image 151/175\n",
            "[INFO] processing image 152/175\n",
            "[INFO] processing image 153/175\n",
            "[INFO] processing image 154/175\n",
            "[INFO] processing image 155/175\n",
            "[INFO] processing image 156/175\n",
            "[INFO] processing image 157/175\n",
            "[INFO] processing image 158/175\n",
            "[INFO] processing image 159/175\n",
            "[INFO] processing image 160/175\n",
            "[INFO] processing image 161/175\n",
            "[INFO] processing image 162/175\n",
            "[INFO] processing image 163/175\n",
            "[INFO] processing image 164/175\n",
            "[INFO] processing image 165/175\n",
            "[INFO] processing image 166/175\n",
            "[INFO] processing image 167/175\n",
            "[INFO] processing image 168/175\n",
            "[INFO] processing image 169/175\n",
            "[INFO] processing image 170/175\n",
            "[INFO] processing image 171/175\n",
            "[INFO] processing image 172/175\n",
            "[INFO] processing image 173/175\n",
            "[INFO] processing image 174/175\n",
            "[INFO] processing image 175/175\n",
            "[INFO] serializing encodings...\n"
          ]
        }
      ],
      "source": [
        "!python encode_faces.py --dataset drive/MyDrive/IoT/dataset --encodings encodings.pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y90MP9K5VJsD",
        "outputId": "9a741e6d-13cb-4568-ac94-18acf10be268"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['pam_beesly',\n",
              " 'pam_beesly',\n",
              " 'pam_beesly',\n",
              " 'pam_beesly',\n",
              " 'pam_beesly',\n",
              " 'pam_beesly',\n",
              " 'pam_beesly',\n",
              " 'pam_beesly',\n",
              " 'pam_beesly',\n",
              " 'pam_beesly',\n",
              " 'pam_beesly',\n",
              " 'pam_beesly',\n",
              " 'pam_beesly',\n",
              " 'pam_beesly',\n",
              " 'pam_beesly',\n",
              " 'pam_beesly',\n",
              " 'pam_beesly',\n",
              " 'pam_beesly',\n",
              " 'pam_beesly',\n",
              " 'pam_beesly',\n",
              " 'pam_beesly',\n",
              " 'pam_beesly',\n",
              " 'pam_beesly',\n",
              " 'pam_beesly',\n",
              " 'pam_beesly',\n",
              " 'pam_beesly',\n",
              " 'pam_beesly',\n",
              " 'pam_beesly',\n",
              " 'andy_bernard',\n",
              " 'andy_bernard',\n",
              " 'andy_bernard',\n",
              " 'andy_bernard',\n",
              " 'andy_bernard',\n",
              " 'andy_bernard',\n",
              " 'andy_bernard',\n",
              " 'andy_bernard',\n",
              " 'andy_bernard',\n",
              " 'andy_bernard',\n",
              " 'andy_bernard',\n",
              " 'andy_bernard',\n",
              " 'andy_bernard',\n",
              " 'andy_bernard',\n",
              " 'andy_bernard',\n",
              " 'andy_bernard',\n",
              " 'andy_bernard',\n",
              " 'andy_bernard',\n",
              " 'andy_bernard',\n",
              " 'andy_bernard',\n",
              " 'oscar_martinez',\n",
              " 'oscar_martinez',\n",
              " 'oscar_martinez',\n",
              " 'oscar_martinez',\n",
              " 'oscar_martinez',\n",
              " 'oscar_martinez',\n",
              " 'oscar_martinez',\n",
              " 'oscar_martinez',\n",
              " 'oscar_martinez',\n",
              " 'oscar_martinez',\n",
              " 'oscar_martinez',\n",
              " 'oscar_martinez',\n",
              " 'oscar_martinez',\n",
              " 'oscar_martinez',\n",
              " 'oscar_martinez',\n",
              " 'kevin_malone',\n",
              " 'kevin_malone',\n",
              " 'kevin_malone',\n",
              " 'kevin_malone',\n",
              " 'kevin_malone',\n",
              " 'kevin_malone',\n",
              " 'kevin_malone',\n",
              " 'kevin_malone',\n",
              " 'kevin_malone',\n",
              " 'kevin_malone',\n",
              " 'kevin_malone',\n",
              " 'kevin_malone',\n",
              " 'kevin_malone',\n",
              " 'kevin_malone',\n",
              " 'kevin_malone',\n",
              " 'kevin_malone',\n",
              " 'kevin_malone',\n",
              " 'kevin_malone',\n",
              " 'kevin_malone',\n",
              " 'michael_scott',\n",
              " 'michael_scott',\n",
              " 'michael_scott',\n",
              " 'michael_scott',\n",
              " 'michael_scott',\n",
              " 'michael_scott',\n",
              " 'michael_scott',\n",
              " 'michael_scott',\n",
              " 'michael_scott',\n",
              " 'michael_scott',\n",
              " 'michael_scott',\n",
              " 'michael_scott',\n",
              " 'michael_scott',\n",
              " 'michael_scott',\n",
              " 'michael_scott',\n",
              " 'michael_scott',\n",
              " 'michael_scott',\n",
              " 'michael_scott',\n",
              " 'michael_scott',\n",
              " 'michael_scott',\n",
              " 'dwight_schrute',\n",
              " 'dwight_schrute',\n",
              " 'dwight_schrute',\n",
              " 'dwight_schrute',\n",
              " 'dwight_schrute',\n",
              " 'dwight_schrute',\n",
              " 'dwight_schrute',\n",
              " 'dwight_schrute',\n",
              " 'dwight_schrute',\n",
              " 'dwight_schrute',\n",
              " 'dwight_schrute',\n",
              " 'dwight_schrute',\n",
              " 'dwight_schrute',\n",
              " 'dwight_schrute',\n",
              " 'dwight_schrute',\n",
              " 'dwight_schrute',\n",
              " 'jim_helpert',\n",
              " 'jim_helpert',\n",
              " 'jim_helpert',\n",
              " 'jim_helpert',\n",
              " 'jim_helpert',\n",
              " 'jim_helpert',\n",
              " 'jim_helpert',\n",
              " 'jim_helpert',\n",
              " 'jim_helpert',\n",
              " 'jim_helpert',\n",
              " 'jim_helpert',\n",
              " 'jim_helpert',\n",
              " 'jim_helpert',\n",
              " 'jim_helpert',\n",
              " 'jim_helpert',\n",
              " 'jim_helpert',\n",
              " 'kelly_kapoor',\n",
              " 'kelly_kapoor',\n",
              " 'kelly_kapoor',\n",
              " 'kelly_kapoor',\n",
              " 'kelly_kapoor',\n",
              " 'kelly_kapoor',\n",
              " 'kelly_kapoor',\n",
              " 'kelly_kapoor',\n",
              " 'kelly_kapoor',\n",
              " 'kelly_kapoor',\n",
              " 'kelly_kapoor',\n",
              " 'kelly_kapoor',\n",
              " 'kelly_kapoor',\n",
              " 'kelly_kapoor',\n",
              " 'kelly_kapoor',\n",
              " 'ryan_howard',\n",
              " 'ryan_howard',\n",
              " 'ryan_howard',\n",
              " 'ryan_howard',\n",
              " 'ryan_howard',\n",
              " 'ryan_howard',\n",
              " 'ryan_howard',\n",
              " 'ryan_howard',\n",
              " 'ryan_howard',\n",
              " 'ryan_howard',\n",
              " 'ryan_howard',\n",
              " 'ryan_howard',\n",
              " 'ryan_howard',\n",
              " 'ryan_howard',\n",
              " 'ryan_howard',\n",
              " 'ryan_howard',\n",
              " 'ryan_howard',\n",
              " 'angela_martin',\n",
              " 'angela_martin',\n",
              " 'angela_martin',\n",
              " 'angela_martin',\n",
              " 'angela_martin',\n",
              " 'angela_martin',\n",
              " 'angela_martin',\n",
              " 'angela_martin',\n",
              " 'angela_martin',\n",
              " 'angela_martin',\n",
              " 'angela_martin',\n",
              " 'angela_martin',\n",
              " 'angela_martin',\n",
              " 'angela_martin',\n",
              " 'angela_martin',\n",
              " 'angela_martin']"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pickle\n",
        "data = pickle.loads(open(\"encodings.pickle\", \"rb\").read())\n",
        "data.keys()\n",
        "data['names']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ffdby7DV28P",
        "outputId": "d8eb7715-0260-44da-af1c-125313f716bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "drive  encode_faces.py\tencodings.pickle  sample_data\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "dbi_c24_Wrb7",
        "outputId": "391b85fe-66a5-4b57-b348-1c75b6d820e7"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_ec96afcf-c473-4bc6-aa56-2ff941b8aaaf\", \"encodings.pickle\", 195220)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.download('encodings.pickle')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "mount_file_id": "1iz-VWqSo2Vpo9-ii_5DRT2R14bExBd3q",
      "authorship_tag": "ABX9TyN7fkJDyrgzqF/K9w5EskLp",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}